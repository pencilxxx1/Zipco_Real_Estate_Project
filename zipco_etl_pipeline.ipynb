{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af263c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: dotenv in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (0.9.9)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.32.3)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.9.10)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.0.43)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from dotenv) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sqlalchemy) (3.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sqlalchemy) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install Necessary Packages\n",
    "!pip install dotenv pandas requests psycopg2-binary sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a41e7dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing necessary librabries needed\n",
    "import psycopg2\n",
    "import requests\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, Float, DateTime, MetaData, ForeignKey\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import dotenv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4874ee85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 500 records for sale.\n",
      "Extracted 500 records for rental.\n",
      "Total records extracted: 1000\n"
     ]
    }
   ],
   "source": [
    "# Extraction Phase: Extract sales and rental data from the Rentcast API\n",
    "\n",
    "# Define API key and URLs\n",
    "API_KEY = '48d189f7a54543799141fb0f8e65db0c'\n",
    "HEADERS = {\"X-Api-Key\": API_KEY, \"accept\": \"application/json\"}\n",
    "SALE_URL = \"https://api.rentcast.io/v1/listings/sale?city=Austin&state=TX&status=Active&limit=500\"\n",
    "RENTAL_URL = \"https://api.rentcast.io/v1/listings/rental/long-term?city=Austin&state=TX&status=Active&limit=500\"\n",
    "\n",
    "# === Extract Function ===\n",
    "def extract_data(url, category):\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data)\n",
    "        df[\"listing_category\"] = category  # add category (sale or rental)\n",
    "        print(f\"Extracted {len(df)} records for {category}.\")\n",
    "        return df\n",
    "    else:\n",
    "        raise Exception(f\"API request failed: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Run extractions\n",
    "sales_df = extract_data(SALE_URL, \"sale\")\n",
    "rentals_df = extract_data(RENTAL_URL, \"rental\")\n",
    "\n",
    "# Combine into one dataset\n",
    "combined_df = pd.concat([sales_df, rentals_df], ignore_index=True)\n",
    "print(f\"Total records extracted: {len(combined_df)}\")\n",
    "\n",
    "# Idempotent save to CSV\n",
    "combined_df.to_csv(\"austin_listings.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b98ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation Phase: Clean and transform data\n",
    "\n",
    "# === Transform Function ===\n",
    "def transform_data(sales_df, rentals_df):\n",
    "    # Combine dataframes\n",
    "    combined_df = pd.concat([sales_df, rental_df], ignore_index=True)\n",
    "    \n",
    "    # Handle missing values (based on schema)\n",
    "    combined_df.fillna({\n",
    "        'addressLine2': '', 'county': '', 'lotSize': 0, 'yearBuilt': 0, 'hoa': {'fee': 0},\n",
    "        'listingType': 'Standard', 'daysOnMarket': 0, 'removedDate': None, 'mlsName': '', 'mlsNumber': '',\n",
    "        'listingAgent': {}, 'listingOffice': {}, 'builder': {}, 'history': {}\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Extract nested fields\n",
    "    combined_df['hoa_fee'] = combined_df['hoa'].apply(lambda x: x.get('fee', 0) if isinstance(x, dict) else 0)\n",
    "    combined_df['agent_name'] = combined_df['listingAgent'].apply(lambda x: x.get('name', '') if isinstance(x, dict) else '')\n",
    "    combined_df['agent_phone'] = combined_df['listingAgent'].apply(lambda x: x.get('phone', '') if isinstance(x, dict) else '')\n",
    "    combined_df['agent_email'] = combined_df['listingAgent'].apply(lambda x: x.get('email', '') if isinstance(x, dict) else '')\n",
    "    combined_df['agent_website'] = combined_df['listingAgent'].apply(lambda x: x.get('website', '') if isinstance(x, dict) else '')\n",
    "    combined_df['office_name'] = combined_df['listingOffice'].apply(lambda x: x.get('name', '') if isinstance(x, dict) else '')\n",
    "    combined_df['office_phone'] = combined_df['listingOffice'].apply(lambda x: x.get('phone', '') if isinstance(x, dict) else '')\n",
    "    # Handle builder for 'New Construction'\n",
    "    combined_df['agent_name'] = combined_df.apply(lambda row: row['builder'].get('name', row['agent_name']) if row.get('listingType') == 'New Construction' else row['agent_name'], axis=1)\n",
    "    # Extend similarly for other builder fields if present\n",
    "    \n",
    "    # Convert dates\n",
    "    date_cols = ['listedDate', 'removedDate', 'createdDate', 'lastSeenDate']\n",
    "    for col in date_cols:\n",
    "        if col in combined_df.columns:\n",
    "            combined_df[col] = pd.to_datetime(combined_df[col], errors='coerce')\n",
    "    \n",
    "    # Flatten history object\n",
    "    history_records = []\n",
    "    for idx, row in combined_df.iterrows():\n",
    "        for history_date, event in row.get('history', {}).items():\n",
    "            if isinstance(event, dict):\n",
    "                event['listing_id'] = row['id']\n",
    "                event['history_date'] = history_date\n",
    "                history_records.append(event)\n",
    "    history_df = pd.DataFrame(history_records)\n",
    "    history_df['listedDate'] = pd.to_datetime(history_df['listedDate'], errors='coerce')\n",
    "    history_df['removedDate'] = pd.to_datetime(history_df['removedDate'], errors='coerce')\n",
    "    \n",
    "    return combined_df, history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9d9d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create snowflake schema in PostgreSQL (using SQLAlchemy)\n",
    "def create_snowflake_schema(engine):\n",
    "    metadata = MetaData()\n",
    "    \n",
    "    # Dimension Tables\n",
    "    dim_state = Table('dim_state', metadata,\n",
    "        Column('state_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('state', String, unique=True)\n",
    "    )\n",
    "\n",
    "    dim_city = Table('dim_city', metadata,\n",
    "        Column('city_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('city', String),\n",
    "        Column('county', String),\n",
    "        Column('state_id', Integer, ForeignKey('dim_state.state_id'))\n",
    "    )\n",
    "\n",
    "    dim_zip = Table('dim_zip', metadata,\n",
    "        Column('zip_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('zip_code', String, unique=True),\n",
    "        Column('city_id', Integer, ForeignKey('dim_city.city_id'))\n",
    "    )\n",
    "\n",
    "    dim_address = Table('dim_address', metadata,\n",
    "        Column('address_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('address_line1', String),\n",
    "        Column('address_line2', String),\n",
    "        Column('formatted_address', String),\n",
    "        Column('zip_id', Integer, ForeignKey('dim_zip.zip_id'))\n",
    "    )\n",
    "\n",
    "    dim_location = Table('dim_location', metadata,\n",
    "        Column('location_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('latitude', Float),\n",
    "        Column('longitude', Float),\n",
    "        Column('address_id', Integer, ForeignKey('dim_address.address_id'))\n",
    "    )\n",
    "\n",
    "    # Property Hierarchy\n",
    "    dim_hoa = Table('dim_hoa', metadata,\n",
    "        Column('hoa_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('fee', Float)\n",
    "    )\n",
    "    \n",
    "    dim_property = Table('dim_property', metadata,\n",
    "        Column('property_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('property_type', String),\n",
    "        Column('bedrooms', Float),\n",
    "        Column('bathrooms', Float),\n",
    "        Column('square_footage', Float),\n",
    "        Column('lot_size', Float),\n",
    "        Column('year_built', Integer),\n",
    "        Column('hoa_id', Integer, ForeignKey('dim_hoa.hoa_id'))\n",
    "    )\n",
    "\n",
    "    # Date Dimension\n",
    "    dim_date = Table('dim_date', metadata,\n",
    "        Column('date_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('full_date', DateTime),\n",
    "        Column('year', Integer),\n",
    "        Column('month', Integer),\n",
    "        Column('day', Integer)\n",
    "    )\n",
    "\n",
    "    # Agent Hierarchy\n",
    "    dim_office = Table('dim_office', metadata,\n",
    "        Column('office_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('name', String),\n",
    "        Column('phone', String)\n",
    "    )\n",
    "    \n",
    "    dim_agent = Table('dim_agent', metadata,\n",
    "        Column('agent_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('name', String),\n",
    "        Column('phone', String),\n",
    "        Column('email', String),\n",
    "        Column('website', String),\n",
    "        Column('type', String),  # 'agent' or 'builder'\n",
    "        Column('office_id', Integer, ForeignKey('dim_office.office_id'))\n",
    "    )\n",
    "\n",
    "    # Fact Table\n",
    "    fact_listings = Table('fact_listings', metadata,\n",
    "        Column('listing_id', String, primary_key=True),\n",
    "        Column('listing_category', String),  # 'sale' or 'rental'\n",
    "        Column('price', Float),\n",
    "        Column('status', String),\n",
    "        Column('listing_type', String),\n",
    "        Column('days_on_market', Integer),\n",
    "        Column('mls_name', String),\n",
    "        Column('mls_number', String),\n",
    "        Column('created_date', DateTime),\n",
    "        Column('last_seen_date', DateTime),\n",
    "        Column('location_id', Integer, ForeignKey('dim_location.location_id')),\n",
    "        Column('property_id', Integer, ForeignKey('dim_property.property_id')),\n",
    "        Column('listed_date_id', Integer, ForeignKey('dim_date.date_id')),\n",
    "        Column('agent_id', Integer, ForeignKey('dim_agent.agent_id'))\n",
    "    )\n",
    "\n",
    "    # History Table (snowflaked from fact)\n",
    "    listing_history = Table('listing_history', metadata,\n",
    "        Column('history_id', Integer, primary_key=True, autoincrement=True),\n",
    "        Column('listing_id', String, ForeignKey('fact_listings.listing_id')),\n",
    "        Column('history_date', String),\n",
    "        Column('event', String),\n",
    "        Column('price', Float),\n",
    "        Column('listing_type', String),\n",
    "        Column('days_on_market', Integer),\n",
    "        Column('listed_date', DateTime),\n",
    "        Column('removed_date', DateTime)\n",
    "    )\n",
    "    metadata.create_all(engine)\n",
    "    \n",
    "    print(\"Snowflake schema created successfully.\")\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "64d2fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create Schema Function ===\n",
    "def create_postgres_schema(engine):\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "                          CREATE TABLE IF NOT EXISTS dim_state (\n",
    "                              state_id SERIAL PRIMARY KEY,\n",
    "                              state VARCHAR UNIQUE\n",
    "                          );\n",
    "                          \n",
    "                            CREATE TABLE IF NOT EXISTS dim_city (\n",
    "                                city_id SERIAL PRIMARY KEY,\n",
    "                                city VARCHAR,\n",
    "                                county VARCHAR,\n",
    "                                state_id INTEGER REFERENCES dim_state(state_id)\n",
    "                            );\n",
    "                            \n",
    "                            CREATE TABLE IF NOT EXISTS dim_zip (\n",
    "                                zip_id SERIAL PRIMARY KEY,\n",
    "                                zip_code VARCHAR UNIQUE,\n",
    "                                city_id INTEGER REFERENCES dim_city(city_id)\n",
    "                            );\n",
    "                        \n",
    "                            CREATE TABLE IF NOT EXISTS dim_address (\n",
    "                                address_id SERIAL PRIMARY KEY,\n",
    "                                address_line1 VARCHAR,\n",
    "                                address_line2 VARCHAR,\n",
    "                                formatted_address VARCHAR,\n",
    "                                zip_id INTEGER REFERENCES dim_zip(zip_id)\n",
    "                            );\n",
    "                            \n",
    "                            CREATE TABLE IF NOT EXISTS dim_location (\n",
    "                                location_id SERIAL PRIMARY KEY,\n",
    "                                latitude FLOAT,\n",
    "                                longitude FLOAT,\n",
    "                                address_id INTEGER REFERENCES dim_address(address_id)\n",
    "                            );\n",
    "                            \n",
    "                            CREATE TABLE IF NOT EXISTS dim_hoa (\n",
    "                                hoa_id SERIAL PRIMARY KEY,\n",
    "                                fee FLOAT\n",
    "                            );\n",
    "                            \n",
    "                            CREATE TABLE IF NOT EXISTS dim_property (\n",
    "                                property_id SERIAL PRIMARY KEY,\n",
    "                                property_type VARCHAR,\n",
    "                                bedrooms FLOAT,\n",
    "                                bathrooms FLOAT,\n",
    "                                square_footage FLOAT,\n",
    "                                lot_size FLOAT,\n",
    "                                year_built INTEGER,\n",
    "                                hoa_id INTEGER REFERENCES dim_hoa(hoa_id)\n",
    "                            );\n",
    "                            \n",
    "                            CREATE TABLE IF NOT EXISTS dim_date (\n",
    "                                date_id SERIAL PRIMARY KEY,\n",
    "                                full_date TIMESTAMP,\n",
    "                                year INTEGER,\n",
    "                                month INTEGER,\n",
    "                                day INTEGER\n",
    "                            );\n",
    "                            \n",
    "                            CREATE TABLE IF NOT EXISTS dim_office (\n",
    "                                office_id SERIAL PRIMARY KEY,\n",
    "                                name VARCHAR,\n",
    "                                phone VARCHAR\n",
    "                            );\n",
    "                            \n",
    "                            CREATE TABLE IF NOT EXISTS dim_agent (\n",
    "                                agent_id SERIAL PRIMARY KEY,\n",
    "                                name VARCHAR,\n",
    "                                phone VARCHAR,\n",
    "                                email VARCHAR,\n",
    "                                website VARCHAR,\n",
    "                                type VARCHAR,  -- 'agent' or 'builder'\n",
    "                                office_id INTEGER REFERENCES dim_office(office_id)\n",
    "                            );\n",
    "                            \n",
    "                            CREATE TABLE IF NOT EXISTS fact_listings (\n",
    "                                listing_id VARCHAR PRIMARY KEY,\n",
    "                                listing_category VARCHAR,  -- 'sale' or 'rental'\n",
    "                                price FLOAT,\n",
    "                                status VARCHAR,\n",
    "                                listing_type VARCHAR,\n",
    "                                days_on_market INTEGER,\n",
    "                                mls_name VARCHAR,\n",
    "                                mls_number VARCHAR,\n",
    "                                created_date TIMESTAMP,\n",
    "                                last_seen_date TIMESTAMP,\n",
    "                                location_id INTEGER REFERENCES dim_location(location_id),\n",
    "                                property_id INTEGER REFERENCES dim_property(property_id),\n",
    "                                listed_date_id INTEGER REFERENCES dim_date(date_id),\n",
    "                                agent_id INTEGER REFERENCES dim_agent(agent_id)\n",
    "                            );\n",
    "                            \n",
    "                            CREATE TABLE IF NOT EXISTS listing_history (\n",
    "                                history_id SERIAL PRIMARY KEY,\n",
    "                                listing_id VARCHAR REFERENCES fact_listings(listing_id),\n",
    "                                history_date VARCHAR,\n",
    "                                event VARCHAR,\n",
    "                                price FLOAT,\n",
    "                                listing_type VARCHAR,\n",
    "                                days_on_market INTEGER,\n",
    "                                listed_date TIMESTAMP,\n",
    "                                removed_date TIMESTAMP\n",
    "                            );\n",
    "                            \n",
    "                            \"\"\"))\n",
    "        print(\"✅ Tables ensured in Postgres.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f64bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime\n",
    "\n",
    "# Load Phase: Loading data into PostgreSQL with Snowflake schema\n",
    "\n",
    "# === Database credentials ===\n",
    "DB_NAME = \"zipco_real_estate_db\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"10Alytics@\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "\n",
    "ENGINE = create_engine(\n",
    "    f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    ")\n",
    "\n",
    "# === API Setup ===\n",
    "API_KEY = \"48d189f7a54543799141fb0f8e65db0c\"\n",
    "HEADERS = {\"X-Api-Key\": API_KEY, \"accept\": \"application/json\"}\n",
    "\n",
    "SALE_URL = \"https://api.rentcast.io/v1/listings/sale?city=Austin&state=TX&status=Active&limit=500\"\n",
    "RENTAL_URL = \"https://api.rentcast.io/v1/listings/rental/long-term?city=Austin&state=TX&status=Active&limit=500\"\n",
    "\n",
    "\n",
    "\n",
    "def load_data(combined_df, history_df):\n",
    "    conn = psycopg2.connect(host=DB_HOST, port=DB_PORT, dbname=DB_NAME, user=DB_USER, password=DB_PASS)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Append to history_df (always insert)\n",
    "    history_df.to_sql('listing_history', ENGINE, if_exists='append', index=False)\n",
    "    \n",
    "    \n",
    "    # Insert into normalized dimensions (example logic; use upserts and retrieve IDs)\n",
    "    for _, row in combined_df.iterrows():\n",
    "        # State\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_state (state) VALUES (%s)\n",
    "            ON CONFLICT (state) DO UPDATE SET state = EXCLUDED.state\n",
    "            RETURNING state_id\n",
    "        \"\"\", (row['state'],))\n",
    "        state_id = cur.fetchone()[0]\n",
    "        \n",
    "        # City\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_city (city, county, state_id) VALUES (%s, %s, %s)\n",
    "            ON CONFLICT (city, state_id) DO UPDATE SET county = EXCLUDED.county\n",
    "            RETURNING city_id\n",
    "        \"\"\", (row['city'], row['county'], state_id))\n",
    "        city_id = cur.fetchone()[0]\n",
    "        \n",
    "        # Zip\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_zip (zip_code, city_id) VALUES (%s, %s)\n",
    "            ON CONFLICT (zip_code) DO UPDATE SET city_id = EXCLUDED.city_id\n",
    "            RETURNING zip_id\n",
    "        \"\"\", (row['zipCode'], city_id))\n",
    "        zip_id = cur.fetchone()[0]\n",
    "        \n",
    "        # Address\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_address (address_line1, address_line2, formatted_address, zip_id)\n",
    "            VALUES (%s, %s, %s, %s)\n",
    "            ON CONFLICT (formatted_address) DO NOTHING\n",
    "            RETURNING address_id\n",
    "        \"\"\", (row['addressLine1'], row['addressLine2'], row['formattedAddress'], zip_id))\n",
    "        address_id = cur.fetchone()[0] if cur.rowcount > 0 else None  # Query if exists\n",
    "        \n",
    "        # Location\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_location (latitude, longitude, address_id) VALUES (%s, %s, %s)\n",
    "            ON CONFLICT (latitude, longitude) DO NOTHING\n",
    "            RETURNING location_id\n",
    "        \"\"\", (row['latitude'], row['longitude'], address_id))\n",
    "        location_id = cur.fetchone()[0] if cur.rowcount > 0 else None\n",
    "        \n",
    "        # HOA\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_hoa (fee) VALUES (%s)\n",
    "            ON CONFLICT (fee) DO NOTHING\n",
    "            RETURNING hoa_id\n",
    "        \"\"\", (row['hoa_fee'],))\n",
    "        hoa_id = cur.fetchone()[0] if cur.rowcount > 0 else None\n",
    "        \n",
    "        # Property\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_property (property_type, bedrooms, bathrooms, square_footage, lot_size, year_built, hoa_id)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "            RETURNING property_id\n",
    "        \"\"\", (row['propertyType'], row['bedrooms'], row['bathrooms'], row['squareFootage'], row['lotSize'], row['yearBuilt'], hoa_id))\n",
    "        property_id = cur.fetchone()[0]\n",
    "        \n",
    "        # Date (for listedDate)\n",
    "        listed_date = row.get('listedDate')\n",
    "        if listed_date:\n",
    "            year, month, day = listed_date.year, listed_date.month, listed_date.day\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO dim_date (full_date, year, month, day) VALUES (%s, %s, %s, %s)\n",
    "                ON CONFLICT (full_date) DO NOTHING\n",
    "                RETURNING date_id\n",
    "            \"\"\", (listed_date, year, month, day))\n",
    "            date_id = cur.fetchone()[0] if cur.rowcount > 0 else None\n",
    "        \n",
    "        # Office\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_office (name, phone) VALUES (%s, %s)\n",
    "            ON CONFLICT (name) DO UPDATE SET phone = EXCLUDED.phone\n",
    "            RETURNING office_id\n",
    "        \"\"\", (row['office_name'], row['office_phone']))\n",
    "        office_id = cur.fetchone()[0]\n",
    "        \n",
    "        # Agent\n",
    "        agent_type = 'builder' if row.get('listingType') == 'New Construction' else 'agent'\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO dim_agent (name, phone, email, website, type, office_id)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s)\n",
    "            RETURNING agent_id\n",
    "        \"\"\", (row['agent_name'], row['agent_phone'], row['agent_email'], row['agent_website'], agent_type, office_id))\n",
    "        agent_id = cur.fetchone()[0]\n",
    "        \n",
    "        # Fact Listings (upsert)\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO fact_listings (listing_id, listing_category, price, status, listing_type, days_on_market,\n",
    "                                       mls_name, mls_number, created_date, last_seen_date, location_id, property_id,\n",
    "                                       listed_date_id, agent_id)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            ON CONFLICT (listing_id) DO UPDATE SET price = EXCLUDED.price, status = EXCLUDED.status  -- Update key fields\n",
    "        \"\"\", (row['id'], row['listing_category'], row['price'], row['status'], row.get('listingType'), row.get('daysOnMarket'),\n",
    "              row.get('mlsName'), row.get('mlsNumber'), row.get('createdDate'), row.get('lastSeenDate'), location_id,\n",
    "              property_id, date_id, agent_id))\n",
    "        \n",
    "        # History\n",
    "        for _, hrow in history_df[history_df['listing_id'] == row['id']].iterrows():\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO listing_history (listing_id, history_date, event, price, listing_type, days_on_market,\n",
    "                                             listed_date, removed_date)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\", (hrow['listing_id'], hrow['history_date'], hrow.get('event'), hrow.get('price'), hrow.get('listingType'),\n",
    "                  hrow.get('daysOnMarket'), hrow.get('listedDate'), hrow.get('removedDate')))\n",
    "    \n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(\"✅ Data loaded into Postgres.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63806bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 500 records for sale.\n",
      "Extracted 500 records for rental.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must specify a fill 'value' or 'method'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m rental_df = extract_data(RENTAL_URL, \u001b[33m'\u001b[39m\u001b[33mrental\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Transform\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m combined_df, history_df = \u001b[43mtransform_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msale_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrental_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Create Schema\u001b[39;00m\n\u001b[32m     12\u001b[39m create_snowflake_schema(ENGINE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtransform_data\u001b[39m\u001b[34m(sales_df, rentals_df)\u001b[39m\n\u001b[32m      5\u001b[39m combined_df = pd.concat([sales_df, rental_df], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Handle missing values (based on schema)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mcombined_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maddressLine2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcounty\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlotSize\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myearBuilt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhoa\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfee\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlistingType\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mStandard\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdaysOnMarket\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mremovedDate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmlsName\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmlsNumber\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlistingAgent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlistingOffice\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbuilder\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhistory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Extract nested fields\u001b[39;00m\n\u001b[32m     15\u001b[39m combined_df[\u001b[33m'\u001b[39m\u001b[33mhoa_fee\u001b[39m\u001b[33m'\u001b[39m] = combined_df[\u001b[33m'\u001b[39m\u001b[33mhoa\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x.get(\u001b[33m'\u001b[39m\u001b[33mfee\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:7384\u001b[39m, in \u001b[36mNDFrame.fillna\u001b[39m\u001b[34m(self, value, method, axis, inplace, limit, downcast)\u001b[39m\n\u001b[32m   7371\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7372\u001b[39m     downcast_k = (\n\u001b[32m   7373\u001b[39m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression\u001b[39;00m\n\u001b[32m   7374\u001b[39m         \u001b[38;5;66;03m# has type \"Union[Dict[Any, Any], None,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   7381\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m downcast.get(k)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   7382\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m7384\u001b[39m res_k = \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdowncast_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[32m   7387\u001b[39m     result[k] = res_k\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\generic.py:7293\u001b[39m, in \u001b[36mNDFrame.fillna\u001b[39m\u001b[34m(self, value, method, axis, inplace, limit, downcast)\u001b[39m\n\u001b[32m   7286\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m ctr <= ref_count:\n\u001b[32m   7287\u001b[39m             warnings.warn(\n\u001b[32m   7288\u001b[39m                 _chained_assignment_warning_method_msg,\n\u001b[32m   7289\u001b[39m                 \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   7290\u001b[39m                 stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   7291\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m7293\u001b[39m value, method = \u001b[43mvalidate_fillna_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   7295\u001b[39m     warnings.warn(\n\u001b[32m   7296\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.fillna with \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmethod\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   7297\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill raise in a future version. Use obj.ffill() or obj.bfill() \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   7300\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   7301\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\util\\_validators.py:293\u001b[39m, in \u001b[36mvalidate_fillna_kwargs\u001b[39m\u001b[34m(value, method, validate_scalar_dict_value)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmissing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clean_fill_method\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMust specify a fill \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmethod\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    295\u001b[39m     method = clean_fill_method(method)\n",
      "\u001b[31mValueError\u001b[39m: Must specify a fill 'value' or 'method'."
     ]
    }
   ],
   "source": [
    "# Connect to Database and Run Complete Pipeline\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Extract\n",
    "    sale_df = extract_data(SALE_URL, 'sale')\n",
    "    rental_df = extract_data(RENTAL_URL, 'rental')\n",
    "    \n",
    "    # Transform\n",
    "    combined_df, history_df = transform_data(sale_df, rental_df)\n",
    "    \n",
    "    # Create Schema\n",
    "    create_snowflake_schema(ENGINE)\n",
    "    \n",
    "    # Load\n",
    "    load_data(combined_df, history_df)\n",
    "    \n",
    "    print(\"ETL Pipeline completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
